{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39727d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: /workspaces/4.TechCatalyst_DE_2025/dev6\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb550f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) is an artificial intelligence model that can process and generate vast amounts of text data. LMLs typically consist of multiple models with their own training datasets, which allows them to learn from user interactions or other natural sources. They are often used for tasks such as natural language processing (NLP), chatbots, sentiment analysis, predictive analytics, and more.\n",
      "\n",
      "LMLs can be trained using various methods, including supervised learning algorithms, unsupervised learning techniques, and reinforcement learning approaches. These models use a variety of data structures and techniques to learn from the interactions or responses users provide, allowing them to improve their performance over time.\n",
      "\n",
      "Some common characteristics of LMLs include:\n",
      "\n",
      "* Large training datasets that contain vast amounts of text data (e.g., billions of words)\n",
      "* Natural language processing tasks such as sentiment analysis, natural language understanding, and topic modeling\n",
      "* Predictive analytics capabilities using historical data or other sources to inform predictions about future outcomes\n",
      "* Chatbots and intelligent agents based on LMLs\n",
      "* Complex applications that require interaction with users through various interfaces, including voice commands, visual displays, or even interactive simulations\n",
      "\n",
      "Examples of large language models include Google's Lua language model, IBM's Knowledge Graph, and the chatbot developed by Amazon. While LMLs can perform many tasks well, they are still relatively rare compared to current NLP technologies like deep learning and computer vision.\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "response = chat(model='smollm2:135m', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'what is a large language model?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a94e9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) is an artificial intelligence model that can process and generate vast amounts of text data. LMLs typically consist of multiple models with their own training datasets, which allows them to learn from user interactions or other natural sources. They are often used for tasks such as natural language processing (NLP), chatbots, sentiment analysis, predictive analytics, and more.\n",
      "\n",
      "LMLs can be trained using various methods, including supervised learning algorithms, unsupervised learning techniques, and reinforcement learning approaches. These models use a variety of data structures and techniques to learn from the interactions or responses users provide, allowing them to improve their performance over time.\n",
      "\n",
      "Some common characteristics of LMLs include:\n",
      "\n",
      "* Large training datasets that contain vast amounts of text data (e.g., billions of words)\n",
      "* Natural language processing tasks such as sentiment analysis, natural language understanding, and topic modeling\n",
      "* Predictive analytics capabilities using historical data or other sources to inform predictions about future outcomes\n",
      "* Chatbots and intelligent agents based on LMLs\n",
      "* Complex applications that require interaction with users through various interfaces, including voice commands, visual displays, or even interactive simulations\n",
      "\n",
      "Examples of large language models include Google's Lua language model, IBM's Knowledge Graph, and the chatbot developed by Amazon. While LMLs can perform many tasks well, they are still relatively rare compared to current NLP technologies like deep learning and computer vision.\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb1f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A large language model (LML) is an artificial intelligence model that can process and generate vast amounts of text data. LMLs typically consist of multiple models with their own training datasets, which allows them to learn from user interactions or other natural sources. They are often used for tasks such as natural language processing (NLP), chatbots, sentiment analysis, predictive analytics, and more.\n",
       "\n",
       "LMLs can be trained using various methods, including supervised learning algorithms, unsupervised learning techniques, and reinforcement learning approaches. These models use a variety of data structures and techniques to learn from the interactions or responses users provide, allowing them to improve their performance over time.\n",
       "\n",
       "Some common characteristics of LMLs include:\n",
       "\n",
       "* Large training datasets that contain vast amounts of text data (e.g., billions of words)\n",
       "* Natural language processing tasks such as sentiment analysis, natural language understanding, and topic modeling\n",
       "* Predictive analytics capabilities using historical data or other sources to inform predictions about future outcomes\n",
       "* Chatbots and intelligent agents based on LMLs\n",
       "* Complex applications that require interaction with users through various interfaces, including voice commands, visual displays, or even interactive simulations\n",
       "\n",
       "Examples of large language models include Google's Lua language model, IBM's Knowledge Graph, and the chatbot developed by Amazon. While LMLs can perform many tasks well, they are still relatively rare compared to current NLP technologies like deep learning and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db15815f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A large language model (LAML) is a type of deep learning model that can be trained on massive amounts of text data from various sources. It uses machine learning algorithms to learn from the relationships between words, phrases, and sentences in natural language. LAMLs are typically used for tasks like sentiment analysis, topic modeling, and language translation. They consist of multiple layers of neural networks, including one or more convolutional neural networks (CNN) and a long short-term memory (LSTM) network, that process the text data to extract patterns, features, and meanings from large amounts of text data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "model = 'smollm2:135m'\n",
    "\n",
    "response = chat(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistance. Your answers are always short, and in bullet points.'},\n",
    "        {'role': 'user', 'content': 'what is a large language model?'}],\n",
    ")\n",
    "Markdown(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27a7e5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LML) refers to an intelligent system that has the ability to process vast amounts of text data and generate human-like responses. LMLs can be created using various programming languages, machine learning models like deep learning or natural language processing, or even standalone programs written in other languages like Python or JavaScript.\n",
      "\n",
      "In a traditional sense, a large language model is essentially an AI system that uses vast amounts of text data to make predictions and decisions about new inputs. This can involve generating responses using patterns learned from the input text, such as sentiment analysis, natural language processing (NLP), or machine learning algorithms like neural networks.\n",
      "\n",
      "LMLs have been successfully applied in a wide range of fields, including customer service interactions, chatbots, text generation tools, and even robotics applications. They can be designed to handle various types of input data, such as user queries, product descriptions, social media posts, or news articles.\n",
      "\n",
      "While LMLs are more commonly associated with AI development, they have been used in other domains like gaming, automation, and education due to their capabilities to process vast amounts of text and generate responses that can be easily understood by humans. However, it's essential to note that traditional NLP techniques may not always perform well on large datasets or require a significant amount of training data for learning effective strategies."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "model = 'smollm2:135m'\n",
    "\n",
    "stream = chat(\n",
    "    model=model,\n",
    "    messages=[{'role': 'user', 'content': 'what is a large language model?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb280bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "\n",
    "\n",
    "def generate_email(subject, recipient_name, additional_info):\n",
    "    \n",
    "    prompt = f\"Write a professional email to {recipient_name} with the subject '{subject}'. Include the following information: {additional_info}\"\n",
    "    \n",
    "    response = chat(\n",
    "        model=\"smollm2:135m\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ])\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06aa408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_writing_assistant():\n",
    "    print(\"Welcome to the Email Writing Assistant!\\n\")\n",
    "    \n",
    "    # Step 4: Gather user input for the email subject, recipient name, and additional information\n",
    "    subject = input(\"Enter the email subject: \")\n",
    "    recipient_name = input(\"Enter the recipient's name: \")\n",
    "    additional_info = input(\"Enter any additional information to include in the email: \")\n",
    "    \n",
    "    # Step 5: Call the 'generate_email' function and display the generated email\n",
    "    email = generate_email(subject, recipient_name, additional_info)\n",
    "    print(f\"Email:\\n{email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8573cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Email Writing Assistant!\n",
      "\n",
      "Email:\n",
      "Subject: Business Opportunity\n",
      "\n",
      "Dear [Name],\n",
      "\n",
      "I hope this message finds you well. I am writing to express my interest in joining your team as a part-time employee, which we have recently decided to accept for the upcoming holiday season and summer break. The position will provide me with valuable work experience through our team meetings, workshops, and on-site training sessions.\n",
      "\n",
      "I believe this role would be an excellent opportunity for me to grow professionally while contributing to your company's success during this period. I am excited about the prospect of working alongside you in a dynamic and collaborative environment that aligns with your business goals.\n",
      "\n",
      "Thank you for considering my application, and I look forward to the possibility of joining your team full-time at your organization. I would be honored if you could provide me with more information on this opportunity, including the responsibilities and benefits associated with being a part-time employee.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "email_writing_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808d360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d9d829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A large language model (LML) refers to an artificial intelligence system that processes vast amounts of text data from various sources and generates new, high-quality content in the form of written or pre-written text. Unlike machines like computers, LMs are programmed with natural language processing capabilities, allowing them to understand human languages and generate responses without being explicitly programmed for a specific domain.\\n\\nLMLs can be used in various applications such as chatbots, virtual assistants, text-to-speech tools, and content creation services. They offer numerous benefits including enhanced user experience, improved accuracy and speed of response times, and increased flexibility with the delivery format (e.g., PDF or HTML). However, LMs also have limitations and potential drawbacks that may need to be carefully considered when designing a system for a specific use case.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user', \n",
    "          'content': 'what is a large language model?'}\n",
    "     ])\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eea671e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The user is seeking information on a topic related to large language models (LMLs), specifically about how they are currently utilized and performance characteristics. The user has requested details regarding their current use, limitations, scalability challenges, and potential future advancements in LML training. They express interest in hearing more about the current state of LML development and its expected improvements over time.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_1 = \"what is a large language model?\"\n",
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user', \n",
    "          'content': prompt_1}\n",
    "     ])\n",
    "\n",
    "history = response.message.content\n",
    "\n",
    "new_prompt = 'What was the question that I asked?'\n",
    "\n",
    "chains = prompt_1 + history + new_prompt \n",
    "\n",
    "response = chat(model='smollm2:135m',\n",
    "     messages=[\n",
    "         {'role': 'user',\n",
    "          'content': chains}\n",
    "     ])\n",
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "068e9abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.1 environment at: /workspaces/4.TechCatalyst_DE_2025/dev6\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea94acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b09e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/4.TechCatalyst_DE_2025/dev6/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chatbot(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"you are a helpful assistant\"}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "import gradio as gr\n",
    "gr.ChatInterface(fn=chatbot, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4175e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e2d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to a class of artificial intelligence algorithms that are capable of generating new content or data that resembles existing content. Unlike traditional AI models, which are primarily designed for classification or prediction tasks, generative AI focuses on creating new outputs based on learned patterns from input data. \n",
      "\n",
      "Key characteristics and techniques of generative AI include:\n",
      "\n",
      "1. **Content Creation**: Generative AI can produce various types of content, including text, images, music, and video. For example, models like GPT (for text generation) and GANs (Generative Adversarial Networks for image generation) fall under this category.\n",
      "\n",
      "2. **Learning from Data**: Generative models are trained on large datasets, where they learn the underlying distribution of the data. Once trained, they can generate new samples that are similar to the training data.\n",
      "\n",
      "3. **Types of Models**:\n",
      "   - **Generative Adversarial Networks (GANs)**: Consist of two neural networks, a generator and a discriminator, that compete against each other to improve the quality of generated outputs.\n",
      "   - **Variational Autoencoders (VAEs)**: Encode input data into a latent space and then decode it back to generate new data, allowing for variations in the rich features learned from the input.\n",
      "   - **Transformers**: Models like OpenAI's GPT or Google's BERT can generate text and are based on transformer architecture, utilizing self-attention mechanisms to understand context.\n",
      "\n",
      "4. **Applications**: Generative AI has wide-ranging applications, including:\n",
      "   - Creative industries (art, music, writing)\n",
      "   - Game design\n",
      "   - Data augmentation for training machine learning models\n",
      "   - Simulating environments for training autonomous systems\n",
      "   - Personalized content generation\n",
      "\n",
      "5. **Ethical Considerations**: The use of generative AI also raises ethical and social concerns, such as the potential for creating deepfakes, misinformation, and issues surrounding copyright and originality.\n",
      "\n",
      "Overall, generative AI represents a rapidly evolving area of artificial intelligence with significant implications for many fields and industries.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model='gpt-4o-mini',\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is Generative AI?\"},\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "629a3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -U -q langchain\n",
    "!uv pip install -U -q langchain-community\n",
    "!uv pip install -U -q langchain-openai\n",
    "!uv pip install -U -q gradio\n",
    "!uv pip install -U -q pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "063a68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from sqlalchemy import create_engine\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2912609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://github.com/laxmimerit/All-CSV-ML-Data-Files-Download/raw/refs/heads/master/db_samples/Chinook.db\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"Chinook.db\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(\"File downloaded successfully\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to download the file\")\n",
    "    print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bab23420",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37a2751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c301532f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[(1, 'For Those About To Rock We Salute You', 1), (2, 'Balls to the Wall', 2)]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM album LIMIT 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466aeb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initializes the ChatOpenAI model with a temperature of 0.7 (controlling randomness) and sets up the SQL toolkit.\n",
    "model='gpt-4o-mini'\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=model)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c49eb71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b21daa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mThe \"Employee\" table seems relevant for finding the number of employees. I will check the schema of the Employee table to understand its structure.  \n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Employee\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Employee\" (\n",
      "\t\"EmployeeId\" INTEGER NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Title\" NVARCHAR(30), \n",
      "\t\"ReportsTo\" INTEGER, \n",
      "\t\"BirthDate\" DATETIME, \n",
      "\t\"HireDate\" DATETIME, \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60), \n",
      "\tPRIMARY KEY (\"EmployeeId\"), \n",
      "\tFOREIGN KEY(\"ReportsTo\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Employee table:\n",
      "EmployeeId\tLastName\tFirstName\tTitle\tReportsTo\tBirthDate\tHireDate\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\n",
      "1\tAdams\tAndrew\tGeneral Manager\tNone\t1962-02-18 00:00:00\t2002-08-14 00:00:00\t11120 Jasper Ave NW\tEdmonton\tAB\tCanada\tT5K 2N1\t+1 (780) 428-9482\t+1 (780) 428-3457\tandrew@chinookcorp.com\n",
      "2\tEdwards\tNancy\tSales Manager\t1\t1958-12-08 00:00:00\t2002-05-01 00:00:00\t825 8 Ave SW\tCalgary\tAB\tCanada\tT2P 2T3\t+1 (403) 262-3443\t+1 (403) 262-3322\tnancy@chinookcorp.com\n",
      "3\tPeacock\tJane\tSales Support Agent\t2\t1973-08-29 00:00:00\t2002-04-01 00:00:00\t1111 6 Ave SW\tCalgary\tAB\tCanada\tT2P 5M5\t+1 (403) 262-3443\t+1 (403) 262-6712\tjane@chinookcorp.com\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find the number of employees, I can simply count the rows in the \"Employee\" table. I'll construct a query to get that count.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \"SELECT COUNT(*) as EmployeeCount FROM Employee;\"  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT COUNT(*) as EmployeeCount FROM Employee;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is correct. Now I will execute it to get the number of employees.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \"SELECT COUNT(*) as EmployeeCount FROM Employee;\"  \u001b[0m\u001b[36;1m\u001b[1;3m[(8,)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: There are 8 employees.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many employees are there?', 'output': 'There are 8 employees.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use the SQL Agent\n",
    "agent.invoke(\"How many employees are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3e1f05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mI should look at the schema of the Customer and Invoice tables, as they are likely to contain information about customers and their purchases. \n",
      "\n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Customer, Invoice\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find out which country's customers have made the most purchases, I will count the number of invoices per country and then order the results accordingly.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \"SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY PurchaseCount DESC LIMIT 10;\"  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY PurchaseCount DESC LIMIT 10;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query appears to be correct. Now I will execute it to find out which country's customers have made the most purchases.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \"SELECT c.Country, COUNT(i.InvoiceId) AS PurchaseCount FROM Customer c JOIN Invoice i ON c.CustomerId = i.CustomerId GROUP BY c.Country ORDER BY PurchaseCount DESC LIMIT 10;\"  \u001b[0m\u001b[36;1m\u001b[1;3m[('USA', 91), ('Canada', 56), ('France', 35), ('Brazil', 35), ('Germany', 28), ('United Kingdom', 21), ('Portugal', 14), ('Czech Republic', 14), ('India', 13), ('Sweden', 7)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer. The countries with the most purchases by customers are as follows: \n",
      "\n",
      "1. USA: 91 purchases\n",
      "2. Canada: 56 purchases\n",
      "3. France: 35 purchases\n",
      "4. Brazil: 35 purchases\n",
      "5. Germany: 28 purchases\n",
      "6. United Kingdom: 21 purchases\n",
      "7. Portugal: 14 purchases\n",
      "8. Czech Republic: 14 purchases\n",
      "9. India: 13 purchases\n",
      "10. Sweden: 7 purchases\n",
      "\n",
      "Final Answer: The countries with the most purchases by customers are USA, Canada, France, Brazil, Germany, United Kingdom, Portugal, Czech Republic, India, and Sweden.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Which country's customers have made the most purchases?\",\n",
       " 'output': 'The countries with the most purchases by customers are USA, Canada, France, Brazil, Germany, United Kingdom, Portugal, Czech Republic, India, and Sweden.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"Which country's customers have made the most purchases?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3780150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: sql_db_list_tables  \n",
      "Action Input: \"\"  \u001b[0m\u001b[38;5;200m\u001b[1;3mAlbum, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\u001b[0m\u001b[32;1m\u001b[1;3mTo find the top countries by total purchases, the most relevant table appears to be the \"Invoice\" table, which likely contains information about purchases, including customer details like country. I will check the schema of the \"Invoice\" and \"Customer\" tables to find the necessary columns to construct my query.\n",
      "\n",
      "Action: sql_db_schema  \n",
      "Action Input: \"Invoice, Customer\"  \u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE \"Customer\" (\n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"FirstName\" NVARCHAR(40) NOT NULL, \n",
      "\t\"LastName\" NVARCHAR(20) NOT NULL, \n",
      "\t\"Company\" NVARCHAR(80), \n",
      "\t\"Address\" NVARCHAR(70), \n",
      "\t\"City\" NVARCHAR(40), \n",
      "\t\"State\" NVARCHAR(40), \n",
      "\t\"Country\" NVARCHAR(40), \n",
      "\t\"PostalCode\" NVARCHAR(10), \n",
      "\t\"Phone\" NVARCHAR(24), \n",
      "\t\"Fax\" NVARCHAR(24), \n",
      "\t\"Email\" NVARCHAR(60) NOT NULL, \n",
      "\t\"SupportRepId\" INTEGER, \n",
      "\tPRIMARY KEY (\"CustomerId\"), \n",
      "\tFOREIGN KEY(\"SupportRepId\") REFERENCES \"Employee\" (\"EmployeeId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Customer table:\n",
      "CustomerId\tFirstName\tLastName\tCompany\tAddress\tCity\tState\tCountry\tPostalCode\tPhone\tFax\tEmail\tSupportRepId\n",
      "1\tLuís\tGonçalves\tEmbraer - Empresa Brasileira de Aeronáutica S.A.\tAv. Brigadeiro Faria Lima, 2170\tSão José dos Campos\tSP\tBrazil\t12227-000\t+55 (12) 3923-5555\t+55 (12) 3923-5566\tluisg@embraer.com.br\t3\n",
      "2\tLeonie\tKöhler\tNone\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t+49 0711 2842222\tNone\tleonekohler@surfeu.de\t5\n",
      "3\tFrançois\tTremblay\tNone\t1498 rue Bélanger\tMontréal\tQC\tCanada\tH2G 1A7\t+1 (514) 721-4711\tNone\tftremblay@gmail.com\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2009-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2009-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2009-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mTo find the top 5 countries by total purchases made, I can aggregate the total purchases from the \"Invoice\" table while grouping by the \"BillingCountry\" column. I will sum up the \"Total\" column for each country and then order the results in descending order to get the top 5 countries.\n",
      "\n",
      "Action: sql_db_query_checker  \n",
      "Action Input: \"SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\"  \u001b[0m\u001b[36;1m\u001b[1;3m```sql\n",
      "SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\n",
      "```\u001b[0m\u001b[32;1m\u001b[1;3mThe query is syntactically correct. I will now execute it to get the results.\n",
      "\n",
      "Action: sql_db_query  \n",
      "Action Input: \"SELECT BillingCountry, SUM(Total) AS TotalPurchases FROM Invoice GROUP BY BillingCountry ORDER BY TotalPurchases DESC LIMIT 5;\"  \u001b[0m\u001b[36;1m\u001b[1;3m[('USA', 523.06), ('Canada', 303.96), ('France', 195.1), ('Brazil', 190.1), ('Germany', 156.48)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer. The top 5 countries by total purchases made are:\n",
      "\n",
      "1. USA: $523.06\n",
      "2. Canada: $303.96\n",
      "3. France: $195.10\n",
      "4. Brazil: $190.10\n",
      "5. Germany: $156.48\n",
      "\n",
      "Final Answer: The top 5 countries by total purchases made are USA, Canada, France, Brazil, and Germany.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the top 5 countries by total purchases made?',\n",
       " 'output': 'The top 5 countries by total purchases made are USA, Canada, France, Brazil, and Germany.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What are the top 5 countries by total purchases made?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cb5aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1536d894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myfiles']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "folders = glob.glob('myfiles')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf35f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "060adcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5400f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Survey of Context Engineering for Large\\nLanguage Models\\nLingrui Mei1,6,† Jiayu Yao1,6,† Yuyao Ge1,6,† Yiwei Wang2 Baolong Bi1,6,†\\nYujun Cai3 Jiazhi Liu1 Mingyu Li1 Zhong-Zhi Li6 Duzhen Zhang6\\nChenlin Zhou4 Jiayi Mao5 Tianze Xia6 Jiafeng Guo1,6,† Shenghua Liu1,6,†,\\n1 Institute of Computing Technology, Chinese Academy of Sciences,\\n2 University of California, Merced,3 The University of Queensland,\\n4 Peking University,5 Tsinghua University,\\n6 University of Chinese Academy of Sciences\\nAbstract: The performance of Large Language Models (LLMs) is fundamentally determined by the contextual\\ninformation provided during inference. This survey introducesContext Engineering, a formal discipline\\nthat transcends simple prompt design to encompass the systematic optimization of information payloads\\nfor LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational\\nComponentsand the sophisticatedImplementations that integrate them into intelligent systems. We first\\nexamine the foundationalComponents: (1)Context Retrieval and Generation, encompassing prompt-based\\ngeneration and external knowledge acquisition; (2)Context Processing, addressing long sequence processing,\\nself-refinement, and structured information integration; and (3)Context Management, covering memory\\nhierarchies, compression, and optimization. We then explore how these components are architecturally\\nintegrated to create sophisticatedSystem Implementations: (1)Retrieval-Augmented Generation (RAG),\\nincluding modular, agentic, and graph-enhanced architectures; (2)Memory Systems, enabling persistent\\ninteractions; (3)Tool-Integrated Reasoning, for function calling and environmental interaction; and (4)\\nMulti-Agent Systems, coordinating communication and orchestration. Through this systematic analysis of over\\n1400 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical\\nresearch gap: a fundamental asymmetry exists between model capabilities. While current models, augmented\\nby advanced context engineering, demonstrate remarkable proficiency inunderstanding complex contexts, they\\nexhibit pronounced limitations ingenerating equally sophisticated, long-form outputs. Addressing this gap is a\\ndefining priority for future research. Ultimately, this survey provides a unified framework for both researchers\\nand engineers advancing context-aware AI.\\n† Also affiliated with: (1)Key Laboratory of Network Data Science and Technology, ICT, CAS; (2)State Key\\nLaboratory of AI Safety\\nCorresponding Author\\nKeywords: Context Engineering, Large Language Models, LLM Agent, Multi-Agent Systems\\nDate: July 21, 2025\\nCode Repository: https://github.com/Meirtz/Awesome-Context-Engineering\\nContact: meilingrui25b@ict.ac.cn, liushenghua@ict.ac.cn\\narXiv:2507.13334v2  [cs.CL]  21 Jul 2025'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a6638e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pikepdf 8.15.1',\n",
       " 'creator': 'arXiv GenPDF (tex2pdf:)',\n",
       " 'creationdate': '',\n",
       " 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu',\n",
       " 'doi': 'https://doi.org/10.48550/arXiv.2507.13334',\n",
       " 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'title': 'A Survey of Context Engineering for Large Language Models',\n",
       " 'trapped': '/False',\n",
       " 'arxivid': 'https://arxiv.org/abs/2507.13334v2',\n",
       " 'source': 'myfiles/2507.13334v2.pdf',\n",
       " 'total_pages': 166,\n",
       " 'page': 0,\n",
       " 'page_label': '1',\n",
       " 'doc_type': 'myfiles'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21dca03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'A Survey of Context Engineering for Large Language Models', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'source': 'myfiles/2507.13334v2.pdf', 'total_pages': 166, 'page': 0, 'page_label': '1', 'doc_type': 'myfiles'}, page_content='A Survey of Context Engineering for Large\\nLanguage Models\\nLingrui Mei1,6,† Jiayu Yao1,6,† Yuyao Ge1,6,† Yiwei Wang2 Baolong Bi1,6,†\\nYujun Cai3 Jiazhi Liu1 Mingyu Li1 Zhong-Zhi Li6 Duzhen Zhang6\\nChenlin Zhou4 Jiayi Mao5 Tianze Xia6 Jiafeng Guo1,6,† Shenghua Liu1,6,†,\\n1 Institute of Computing Technology, Chinese Academy of Sciences,\\n2 University of California, Merced,3 The University of Queensland,\\n4 Peking University,5 Tsinghua University,\\n6 University of Chinese Academy of Sciences\\nAbstract: The performance of Large Language Models (LLMs) is fundamentally determined by the contextual\\ninformation provided during inference. This survey introducesContext Engineering, a formal discipline\\nthat transcends simple prompt design to encompass the systematic optimization of information payloads\\nfor LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational\\nComponentsand the sophisticatedImplementations that integrate them into intelligent systems. We first\\nexamine the foundationalComponents: (1)Context Retrieval and Generation, encompassing prompt-based\\ngeneration and external knowledge acquisition; (2)Context Processing, addressing long sequence processing,\\nself-refinement, and structured information integration; and (3)Context Management, covering memory\\nhierarchies, compression, and optimization. We then explore how these components are architecturally\\nintegrated to create sophisticatedSystem Implementations: (1)Retrieval-Augmented Generation (RAG),\\nincluding modular, agentic, and graph-enhanced architectures; (2)Memory Systems, enabling persistent\\ninteractions; (3)Tool-Integrated Reasoning, for function calling and environmental interaction; and (4)\\nMulti-Agent Systems, coordinating communication and orchestration. Through this systematic analysis of over\\n1400 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical\\nresearch gap: a fundamental asymmetry exists between model capabilities. While current models, augmented\\nby advanced context engineering, demonstrate remarkable proficiency inunderstanding complex contexts, they\\nexhibit pronounced limitations ingenerating equally sophisticated, long-form outputs. Addressing this gap is a\\ndefining priority for future research. Ultimately, this survey provides a unified framework for both researchers\\nand engineers advancing context-aware AI.\\n† Also affiliated with: (1)Key Laboratory of Network Data Science and Technology, ICT, CAS; (2)State Key\\nLaboratory of AI Safety\\nCorresponding Author\\nKeywords: Context Engineering, Large Language Models, LLM Agent, Multi-Agent Systems\\nDate: July 21, 2025\\nCode Repository: https://github.com/Meirtz/Awesome-Context-Engineering\\nContact: meilingrui25b@ict.ac.cn, liushenghua@ict.ac.cn\\narXiv:2507.13334v2  [cs.CL]  21 Jul 2025')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3490661",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -U -q langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c62bccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31426d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dec74e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f95fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name,\n",
    "           embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87d3b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks,\n",
    "                                    embedding=embeddings,\n",
    "                                    persist_directory=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "745ec82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 166 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "67173e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "170e8898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(id='1a7941be-35ed-4244-9fd2-812478c5db60', metadata={'creationdate': '', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'total_pages': 166, 'title': 'A Survey of Context Engineering for Large Language Models', 'page_label': '2', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'doc_type': 'myfiles', 'creator': 'arXiv GenPDF (tex2pdf:)', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'trapped': '/False', 'page': 1, 'producer': 'pikepdf 8.15.1', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'source': 'myfiles/2507.13334v2.pdf', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/'}, page_content='Contents\\n1 Introduction 4\\n2 Related Work 5\\n3 Why Context Engineering? 7\\n3.1 Definition of Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3.2 Why Context Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.1 Current Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.2 Performance Enhancement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.3 Resource Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2.4 Future Potential . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4 Foundational Components 12\\n4.1 Context Retrieval and Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n4.1.1 Prompt Engineering and Context Generation . . . . . . . . . . . . . . . . . . . . . . . 13\\n4.1.2 External Knowledge Retrieval . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.1.3 Dynamic Context Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n4.2 Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.1 Long Context Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2.2 Contextual Self-Refinement and Adaptation . . . . . . . . . . . . . . . . . . . . . . . 18\\n4.2.3 Multimodal Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n4.2.4 Relational and Structured Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4.3 Context Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.1 Fundamental Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n4.3.2 Memory Hierarchies and Storage Architectures . . . . . . . . . . . . . . . . . . . . . 24\\n4.3.3 Context Compression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4.3.4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\n5 System Implementations 27\\n5.1 Retrieval-Augmented Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n5.1.1 Modular RAG Architectures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n2'), 0.6291267834796594)\n"
     ]
    }
   ],
   "source": [
    "result = vectorstore.similarity_search_with_relevance_scores(\"What is context engineering?\", k=5)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f53e0721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(id='2d3b87bd-c2bb-4eff-b602-9a0aa009f551', metadata={'trapped': '/False', 'source': 'myfiles/2507.13334v2.pdf', 'total_pages': 166, 'creationdate': '', 'page_label': '10', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'A Survey of Context Engineering for Large Language Models', 'page': 9, 'doc_type': 'myfiles', 'author': 'Lingrui Mei; Jiayu Yao; Yuyao Ge; Yiwei Wang; Baolong Bi; Yujun Cai; Jiazhi Liu; Mingyu Li; Zhong-Zhi Li; Duzhen Zhang; Chenlin Zhou; Jiayi Mao; Tianze Xia; Jiafeng Guo; Shenghua Liu', 'creator': 'arXiv GenPDF (tex2pdf:)', 'doi': 'https://doi.org/10.48550/arXiv.2507.13334', 'arxivid': 'https://arxiv.org/abs/2507.13334v2', 'producer': 'pikepdf 8.15.1', 'license': 'http://arxiv.org/licenses/nonexclusive-distrib/1.0/'}, page_content='Dimension Prompt Engineering Context Engineering\\nModel C=prompt (static string) C=A(c1,c2, . . . ,cn)(dynamic, structured assembly)\\nTarget arg maxpromptPθ(Y|prompt) F∗ =arg maxFEτ∼T[Reward(Pθ(Y|CF(τ)),Y∗τ)]\\nComplexity Manual or automated search over a string space.System-level optimization ofF={A,Retrieve,Select, . . .}.\\nInformationInformation content is fixed within the prompt.Aims to maximize task-relevant information under constraint|C| ≤Lmax.\\nState Primarily stateless. Inherently stateful, with explicit components forcmemandcstate.\\nScalability Brittleness increases with length and complexity.Manages complexity through modular composition.\\nError AnalysisManual inspection and iterative refinement.Systematic evaluation and debugging of individual context functions.\\nTable 1: Comparison of Prompt Engineering and Context Engineering Paradigms.\\nComparisonofParadigms TheformalizationofContextEngineeringhighlightsitsfundamentaldistinctions\\nfrom traditional prompt engineering. The following table summarizes the key differences.\\nIn summary, Context Engineering provides the formal, systematic framework required to build, under-\\nstand, and optimize the sophisticated, context-aware AI systems that are coming to define the future of the\\nfield. It shifts the focus from the “art” of prompt design to the “science” of information logistics and system\\noptimization.\\nContext Scaling Context scaling encompasses two fundamental dimensions that collectively define the\\nscope and sophistication of contextual information processing. The first dimension,length scaling, addresses\\nthecomputationalandarchitecturalchallengesofprocessingultra-longsequences,extendingcontextwindows\\nfrom thousands to millions of tokens while maintaining coherent understanding across extended narratives,\\ndocuments, and interactions. This involves sophisticated attention mechanisms, memory management\\ntechniques, and architectural innovations that enable models to maintain contextual coherence over vastly\\nextended input sequences.\\nThe second, equally critical dimension ismulti-modal and structural scaling, which expands context\\nbeyond simple text to encompass multi-dimensional, dynamic, cross-modal information structures. This\\nincludes temporal context (understanding time-dependent relationships and sequences), spatial context\\n(interpreting location-based and geometric relationships), participant states (tracking multiple entities and\\ntheir evolving conditions), intentional context (understanding goals, motivations, and implicit objectives),\\nand cultural context (interpreting communication within specific social and cultural frameworks).\\nModern context engineering must address both dimensions simultaneously, as real-world applications\\nrequire models to process not only lengthy textual information but also diverse data types including struc-\\ntured knowledge graphs, multimodal inputs (text, images, audio, video), temporal sequences, and implicit\\ncontextual cues that humans naturally understand. This multi-dimensional approach to context scaling\\nrepresents a fundamental shift from parameter scaling toward developing systems capable of understanding\\ncomplex, ambiguous contexts that mirror the nuanced nature of human intelligence in facing a complex\\nworld [1044].\\n10'),\n",
       " 0.5274813175201416)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = vectorstore.similarity_search_with_score(\"what is the difference between prompt engineering and context engineering\", k=3)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a36910fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13475/2674871582.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "model='gpt-4o-mini'\n",
    "\n",
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=model)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfa65dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain what is the difference between prompt engineering and context engineering\"\n",
    "result = conversation_chain.invoke({\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f89a0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering treats the context as a monolithic, static string of text, focusing on crafting precise and contextually rich prompts for effective communication with language models. In contrast, context engineering re-conceptualizes context as a dynamically structured set of informational components that are sourced, filtered, and formatted by various functions. This approach emphasizes systematic optimization, modular composition, and the management of complex, multi-dimensional contexts, enabling models to process extended sequences and diverse data types more effectively. Overall, context engineering shifts the focus from the \"art\" of prompt design to the \"science\" of information logistics and system optimization.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "531a1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"explain in bullet points what is dynamic context assembly\"\n",
    "result = conversation_chain.invoke({\"question\":query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bf7783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Dynamic context assembly refers to the orchestration of acquired information components into coherent and task-optimized contexts.\\n- It aims to maximize the performance of language models while considering computational constraints.\\n- The assembly function encompasses various strategies, including:\\n  - Template-based formatting\\n  - Priority-based selection\\n  - Adaptive composition based on task requirements and model capabilities\\n- Contemporary orchestration mechanisms manage:\\n  - Agent selection\\n  - Context distribution\\n  - Interaction flow control in multi-agent systems\\n- The goal is to enable effective cooperation among agents through:\\n  - User input processing\\n  - Contextual distribution\\n  - Optimal agent selection based on capability assessment\\n- Advanced frameworks may include components for:\\n  - Intent recognition\\n  - Contextual memory maintenance\\n  - Task dispatching for intelligent coordination across domain-specific agents.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd18c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
